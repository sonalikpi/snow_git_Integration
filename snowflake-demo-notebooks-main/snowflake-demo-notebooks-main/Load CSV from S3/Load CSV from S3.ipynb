{
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13f35857-7833-4c7a-820b-421f7156fc94",
      "metadata": {
        "name": "cell1",
        "collapsed": false
      },
      "source": "# How to load CSV files from stage to Snowflake Notebooks \ud83d\udcc1\n\nIn this example, we will show how you can load a CSV file from stage and create a table with Snowpark. \n\nFirst, let's use the `get_active_session` command to get the [session](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.Session#snowflake.snowpark.Session) context variable to work with Snowpark as follows:"
    },
    {
      "cell_type": "code",
      "id": "4babf2c9-2d53-48dc-9b2e-07cda9bcc03c",
      "metadata": {
        "language": "python",
        "name": "cell2",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nprint(session)",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "b8151396-3ae3-4991-8ef0-be82fc33f363",
      "metadata": {
        "name": "cell3",
        "collapsed": false
      },
      "source": "Next, we will create an [external stage](https://docs.snowflake.com/en/sql-reference/sql/create-stage) that references data files stored in a location outside of Snowflake, in this case, the data lives in a [S3 bucket](https://docs.snowflake.com/en/user-guide/data-load-s3-create-stage)."
    },
    {
      "cell_type": "code",
      "id": "f7d7f866-a698-457f-8bd0-4deff26ba329",
      "metadata": {
        "language": "sql",
        "name": "cell4",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "CREATE STAGE IF NOT EXISTS TASTYBYTE_STAGE \n\tURL = 's3://sfquickstarts/frostbyte_tastybytes/';",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "614a9f59-b202-4102-81e8-192b66b656fd",
      "metadata": {
        "name": "cell5",
        "collapsed": false
      },
      "source": "Let's take a look at the files in the stage."
    },
    {
      "cell_type": "code",
      "id": "18fdb36a-f3f6-46b0-92db-e06a28b14867",
      "metadata": {
        "language": "sql",
        "name": "cell6",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "LS @TASTYBYTE_STAGE/app/app_orders;",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "9feb2dbb-8752-41c1-bd88-f2075e89f4ea",
      "metadata": {
        "name": "cell7",
        "collapsed": false
      },
      "source": "We can use [Snowpark DataFrameReader](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.14.0/api/snowflake.snowpark.DataFrameReader) to read in the CSV file.\n\nBy using the `infer_schema = True` option, Snowflake will automatically infer the schema based on data types present in CSV file, so that you don't need to specify the schema beforehand. "
    },
    {
      "cell_type": "code",
      "id": "2bf5c75a-b4e8-4212-a645-b8d63102757d",
      "metadata": {
        "language": "python",
        "name": "cell8",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "# Create a DataFrame that is configured to load data from the CSV file.\ndf = session.read.options({\"infer_schema\":True}).csv('@TASTYBYTE_STAGE/app/app_orders/app_order_detail.csv.gz')",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "81196d0e-3979-46f1-b11d-871082171f61",
      "metadata": {
        "language": "python",
        "name": "cell9",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "df",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "94b0bc16-c31c-4cf0-8bf0-f2fdcdbfac0f",
      "metadata": {
        "name": "cell10",
        "collapsed": false
      },
      "source": "Now that the data is loaded into a Snowpark DataFrame, we can work with the data using [Snowpark DataFrame API](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.DataFrame). \n\nFor example, I can compute descriptive statistics on the columns."
    },
    {
      "cell_type": "code",
      "id": "bac152b7-8c98-4e0a-9ecc-42f2c104f49d",
      "metadata": {
        "language": "python",
        "name": "cell11",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "df.describe()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "b5ff2c51-66d9-4ca4-a060-0b40286ae37c",
      "metadata": {
        "name": "cell12",
        "collapsed": false
      },
      "source": "We can write the dataframe into a table called `APP_ORDER` and query it with SQL. "
    },
    {
      "cell_type": "code",
      "id": "1f7b5940-47cb-438c-a666-817267b4bf39",
      "metadata": {
        "language": "python",
        "name": "cell13",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "df.write.mode(\"overwrite\").save_as_table(\"APP_ORDER\")",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "90e335b9-f60a-4971-aec8-288f0470340b",
      "metadata": {
        "language": "sql",
        "name": "cell14",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "-- Preview the newly created APP_ORDER table\nSELECT * from APP_ORDER;",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "966f07d5-d246-49da-b133-6ab39fb0578d",
      "metadata": {
        "name": "cell15",
        "collapsed": false
      },
      "source": "Finally, we show how you can read the table back to Snowpark via the `session.table` syntax."
    },
    {
      "cell_type": "code",
      "id": "76dd9c74-019d-47ff-a462-10499503bace",
      "metadata": {
        "language": "python",
        "name": "cell16",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "df = session.table(\"APP_ORDER\")\ndf",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "ca22f85f-9073-44e6-a255-e34155b19bbb",
      "metadata": {
        "name": "cell17",
        "collapsed": false
      },
      "source": "From here, you can continue to query and process the data. "
    },
    {
      "cell_type": "code",
      "id": "2ff779a9-c9ba-434d-b098-2564b9b6e337",
      "metadata": {
        "language": "python",
        "name": "cell18",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "df.groupBy('\"c4\"').count()",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "792359f0-42fa-4639-b286-f8a8afeb1188",
      "metadata": {
        "language": "sql",
        "name": "cell19",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "-- Teardown table and stage created as part of this example\nDROP TABLE APP_ORDER;\nDROP STAGE TASTYBYTE_STAGE;",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "d149c3c7-4a48-446e-a75f-beefc949790b",
      "metadata": {
        "name": "cell20",
        "collapsed": false
      },
      "source": "### Conclusion\nIn this example, we took a look at how you can load a CSV file from an external stage to process and query the data in your notebook using Snowpark. You can learn more about how to work with your data using Snowpark Python [here](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)."
    }
  ]
}