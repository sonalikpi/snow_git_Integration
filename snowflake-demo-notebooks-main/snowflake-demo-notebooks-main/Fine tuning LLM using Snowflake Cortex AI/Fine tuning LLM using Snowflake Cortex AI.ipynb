{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5fb84a2-1348-4f6c-beb6-88f9d3bacb60",
   "metadata": {
    "name": "getting_started",
    "collapsed": false
   },
   "source": "Welcome to Snowflake! This guide shows how to fine-tune a foundational LLM (Large Language Model) using Cortex Serverless SQL functions. \n\nIn this exercise, you will:\n\n* Use `mistral-large` model to categorize customer support tickets\n* Prepare training data for fine-tuning using `mistral-7b` to generate annotations\n* Fine-tune `mistral-7b` to achieve the accuracy of `mistral-large` at fraction of cost\n* Generate custom email copy for each support ticket using the fine-tuned model"
  },
  {
   "cell_type": "markdown",
   "id": "b5727103-e592-4879-bb1f-5f7384994e46",
   "metadata": {
    "collapsed": false,
    "name": "step_1"
   },
   "source": "## Import Snowpark and create Snowpark session"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7310e0-4362-4cd2-bad9-fd70854ef709",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "import snowflake.snowpark.functions as F\nimport streamlit as st\nimport altair as alt"
  },
  {
   "cell_type": "code",
   "id": "8f58e3e3-9cf9-4ed7-ab8c-e82cd46a48e9",
   "metadata": {
    "language": "python",
    "name": "snowpark_session",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a34347c-0a82-4cac-950a-1b9c848c6200",
   "metadata": {
    "collapsed": false,
    "name": "step_2"
   },
   "source": "## Load customer support ticket data from AWS S3 into a Snowflake table\nThis section walks you through the steps to:\n\n- Create a database and schema.\n- Create a file format for the data.\n- Create an external stage.\n- Create a table.\n- Load the data from external stage."
  },
  {
   "cell_type": "code",
   "id": "1340cca8-2531-4824-98a5-1b5bdb4bcdb7",
   "metadata": {
    "language": "sql",
    "name": "create_database_and_schema",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE DATABASE VINO_DB;\nCREATE OR REPLACE SCHEMA VINO_SCHEMA;\nUSE SCHEMA VINO_DB.VINO_SCHEMA;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3e6d236-8eba-4cf0-815c-97567820d2c8",
   "metadata": {
    "language": "sql",
    "name": "create_fileformat_and_stage",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE or REPLACE file format csvformat\n  SKIP_HEADER = 1\n  FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n  type = 'CSV';\n\nCREATE or REPLACE stage support_tickets_data_stage\n  file_format = csvformat\n  url = 's3://sfquickstarts/finetuning_llm_using_snowflake_cortex_ai/';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d995993-ae6a-4992-960e-0f2e9e621deb",
   "metadata": {
    "language": "sql",
    "name": "create_table"
   },
   "outputs": [],
   "source": "CREATE or REPLACE TABLE SUPPORT_TICKETS (\n  ticket_id VARCHAR(60),\n  customer_name VARCHAR(60),\n  customer_email VARCHAR(60),\n  service_type VARCHAR(60),\n  request VARCHAR,\n  contact_preference VARCHAR(60)\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ef554db-071b-49de-8966-c871e40866f0",
   "metadata": {
    "language": "sql",
    "name": "load_data"
   },
   "outputs": [],
   "source": "COPY into SUPPORT_TICKETS\n  from @support_tickets_data_stage;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b323573-5756-4b57-8f5a-e441853a955d",
   "metadata": {
    "language": "python",
    "name": "read_from_table",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "df_support_tickets = session.table('support_tickets')\ndf_support_tickets.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "17ed99f8-90ad-48a9-ba82-696b73d364ee",
   "metadata": {
    "name": "step_3",
    "collapsed": false
   },
   "source": "## Categorize Support Tickets: \nBy prompting both `mistral-large` and `mistral-7b` models, let's categorize the customer support tickets into one of 5 classes, based on the complaints.\n\n- Roaming fees\n- Slow data speed\n- Lost phone\n- Add new line\n- Closing account"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b42f0d-61f8-4feb-8953-709411c95955",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "model_prompt"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an agent that helps organize requests that come to our support team. \n",
    "\n",
    "The request category is the reason why the customer reached out. These are the possible types of request categories:\n",
    "\n",
    "Roaming fees\n",
    "Slow data speed\n",
    "Lost phone\n",
    "Add new line\n",
    "Closing account\n",
    "\n",
    "Try doing it for this request and return only the request category only.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25748d6-35f3-41c0-8b8f-3578f363be83",
   "metadata": {
    "collapsed": false,
    "name": "prompting_mistral_large"
   },
   "source": "## Let's use `mistral-large` to categorize the tickets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56693c61-19d6-47aa-bec5-95d04ed52737",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "mistral_large"
   },
   "outputs": [],
   "source": "mistral_large_response_sql = f\"\"\" select ticket_id, \n                                        request, \n                                        trim(snowflake.cortex.complete('mistral-large',\n                                                                        concat('{prompt}',\n                                                                        request)),'\\n') as mistral_large_response\n                                    from support_tickets\n                                \"\"\"\n\ndf_mistral_large_response = session.sql(mistral_large_response_sql)\ndf_mistral_large_response.show()"
  },
  {
   "cell_type": "markdown",
   "id": "ab397503-3806-4bc9-8f59-7f84da848bf4",
   "metadata": {
    "collapsed": false,
    "name": "prompting_mistral_7b"
   },
   "source": "## Let's now use `mistral-7b` to categorize the tickets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb995b6-8242-4b8c-82e4-621256e39fe7",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "mistral_7b"
   },
   "outputs": [],
   "source": "mistral_7b_response_sql = f\"\"\" select ticket_id,\n                                    trim(snowflake.cortex.complete('mistral-7b',\n                                                                        concat('{prompt}',\n                                                                        request)),'\\n') as mistral_7b_response\n                                from support_tickets\n                            \"\"\"\n\ndf_mistral_7b_response = session.sql(mistral_7b_response_sql)\ndf_mistral_7b_response.show()"
  },
  {
   "cell_type": "markdown",
   "id": "34928608-9ced-4be9-b506-ebf8fe8cbf6d",
   "metadata": {
    "name": "compare_responses",
    "collapsed": false
   },
   "source": "## Let's compare the categorization results of both models\n\nAs you can see in the results below, the `mistral-large` does a good job of returning the ticket categories only. However, the `mistral-7b` returns additional text which is not the expected behavior.\n\nCan we fine-tune `mistral-7b` to achieve better accuracy instead of using a larger model?"
  },
  {
   "cell_type": "code",
   "id": "c3d80ead-6b13-4757-b262-9c1e4699b8a5",
   "metadata": {
    "language": "python",
    "name": "compare_model_responses",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df_llms = df_mistral_large_response.join(df_mistral_7b_response,'ticket_id')\ndf_llms.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7f8cd51b-96d8-44d5-adc4-50a1b62fc914",
   "metadata": {
    "collapsed": false,
    "name": "step_4"
   },
   "source": "## Prepare/ Generate dataset to fine-tune `mistral-7b`\n\n- For the next step, let's use `mistral-large` model to categorize the support tickets, and create training dataset from the model responses. \n\n- Let us then use this dataset to fine-tune the smaller `mistral-7b` model.\n\n- The annotated dataset is saved into `support_tickets_finetune` table in Snowflake."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c2111-f220-4be2-b907-4b2a140fdea4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "prepare_dataset"
   },
   "outputs": [],
   "source": "df_fine_tune = df_mistral_large_response.with_column(\"prompt\", \n                                                     F.concat(F.lit(prompt),F.lit(\" \"),F.col(\"request\"))).\\\n                                        select(\"ticket_id\",\"prompt\",\"mistral_large_response\")\n\ndf_fine_tune.write.mode('overwrite').save_as_table('support_tickets_finetune')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07123242-032c-4c28-aa00-be737c45af80",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "train_test_split"
   },
   "outputs": [],
   "source": [
    "train_df, eval_df = session.table(\"support_tickets_finetune\").random_split(weights=[0.8, 0.2], seed=42)\n",
    "train_df.write.mode('overwrite').save_as_table('support_tickets_train')\n",
    "eval_df.write.mode('overwrite').save_as_table('support_tickets_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86dfda-75f7-451d-bf1b-2e19b0d938a5",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "train_sample"
   },
   "outputs": [],
   "source": [
    "session.table('support_tickets_train').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07d19f-415e-4f5a-bc6d-c6fe3b046577",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "eval_sample"
   },
   "outputs": [],
   "source": [
    "session.table('support_tickets_eval').show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce01346-2b85-425f-9675-d3a2626c27f6",
   "metadata": {
    "collapsed": false,
    "name": "step_5"
   },
   "source": "## Fine-tune `mistral-7b` using Cortex\n\nLet's fine-tune using the annotated dataset from `support_tickets_finetune` table\n\n- Use `snowflake.cortex.finetune()` to run the fine-tuning job\n- Monitor progress\n- Run inference on the fine-tuned model"
  },
  {
   "cell_type": "code",
   "id": "3c881a0c-c495-4a39-9630-9d48aa720b19",
   "metadata": {
    "language": "sql",
    "name": "finetuning",
    "collapsed": false
   },
   "outputs": [],
   "source": "select snowflake.cortex.finetune('CREATE', \n                                    'VINO_DB.VINO_SCHEMA.SUPPORT_TICKETS_FINETUNED_MISTRAL_7B', \n                                    'mistral-7b', \n                                    'SELECT prompt, mistral_large_response as completion from VINO_DB.VINO_SCHEMA.support_tickets_train', \n                                    'SELECT prompt, mistral_large_response as completion from VINO_DB.VINO_SCHEMA.support_tickets_eval');",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1db774c3-b9cc-444e-84b5-7de8e61d680a",
   "metadata": {
    "collapsed": false,
    "name": "monitor_status"
   },
   "source": "To see the progress of the fine-tuning job, copy the `job id` from the above cell result and update the second parameter of the `finetune()` function."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21516fe-e328-4793-9953-7d5d6b7e616c",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "describe_job"
   },
   "outputs": [],
   "source": "select snowflake.cortex.finetune('DESCRIBE', 'CortexFineTuningWorkflow_3b54b820-7173-4a07-83ad-5645bd4c45ec');"
  },
  {
   "cell_type": "markdown",
   "id": "2c6c7a29-681b-43c1-b977-f4cacceed5bf",
   "metadata": {
    "collapsed": false,
    "name": "inference"
   },
   "source": "## Inference using fine-tuned model \n\nLet's use this fine-tuned `mistral-7b` model that we named `SUPPORT_TICKETS_FINETUNED_MISTRAL_7B` on the eval dataset to categorize the tickets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd2e43-fd73-4dbb-ae14-534d1902a651",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "run_inference",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "fine_tuned_model_name = 'SUPPORT_TICKETS_FINETUNED_MISTRAL_7B'\nfine_tuned_response_sql = f\"\"\"\n        select ticket_id, \n            request,\n            trim(snowflake.cortex.complete('{fine_tuned_model_name}',concat('{prompt}',request)),'\\n') as fine_tuned_mistral_7b_model_response\n        from support_tickets\n        \"\"\"\n\ndf_fine_tuned_mistral_7b_response = session.sql(fine_tuned_response_sql)\ndf_fine_tuned_mistral_7b_response"
  },
  {
   "cell_type": "markdown",
   "id": "c402c49f-0d48-428b-a71c-85b8b58d6916",
   "metadata": {
    "name": "visualize_categories",
    "collapsed": false
   },
   "source": "Let's visualize the ticket categories and the number of tickets per category"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeef951-0c61-4954-a3ce-5fac3a6c0359",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "tickets_per_category"
   },
   "outputs": [],
   "source": "df = df_fine_tuned_mistral_7b_response.group_by('fine_tuned_mistral_7b_model_response').\\\n                                        agg(F.count(\"*\").as_('COUNT'))\n\nst.subheader(\"Number of requests per category\")\nchart = alt.Chart(df.to_pandas()).mark_bar().encode(\n    y=alt.Y('FINE_TUNED_MISTRAL_7B_MODEL_RESPONSE:N', sort=\"-x\"),\n    x=alt.X('COUNT:Q',),\n    color=alt.Color('FINE_TUNED_MISTRAL_7B_MODEL_RESPONSE:N', scale=alt.Scale(scheme='category10'), legend=None),\n).properties(height=400)\n\nst.altair_chart(chart, use_container_width=True)"
  },
  {
   "cell_type": "markdown",
   "id": "49adff6f-6e67-440c-a260-f6f857a9ec22",
   "metadata": {
    "collapsed": false,
    "name": "step_6"
   },
   "source": "## Streamlit application to auto-generate custom emails and text messages\n\nSince we are able to rightly categorize the customer support tickets based on root cause, the next step is to auto-generate custom email responses for each support ticket.\n\nLet's build a Streamlit app that allows us to choose between these 4 LLMs to generate the email copy:\n- `snowflake-arctic`\n- `llama3-8b`\n- `mistral-large`\n- `reka-flash`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457ce4d-181b-4857-a257-5f40257e073c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "streamlit_app"
   },
   "outputs": [],
   "source": [
    "st.subheader(\"Auto-generate custom emails or text messages\")\n",
    "\n",
    "with st.container():\n",
    "    with st.expander(\"Edit prompt and select LLM\", expanded=True):\n",
    "        entered_prompt = st.text_area('Prompt',\"\"\"Please write an email or text promoting a new plan that will save customers total costs. If the customer requested to be contacted by text message, write text message response in less than 25 words, otherwise write email response in maximum 100 words.\"\"\")\n",
    "    \n",
    "        with st.container():\n",
    "            left_col,right_col = st.columns(2)\n",
    "            with left_col:\n",
    "                selected_category = st.selectbox('Select category',('Roaming fees', 'Closing account', 'Add new line', 'Slow data speed'))\n",
    "            with right_col:\n",
    "                selected_llm = st.selectbox('Select LLM',('snowflake-arctic','llama3-8b','mistral-large', 'reka-flash',))\n",
    "\n",
    "with st.container():\n",
    "    _,mid_col,_ = st.columns([.4,.3,.3])\n",
    "    with mid_col:\n",
    "        generate_template = st.button('Generate messages ⚡',type=\"primary\")\n",
    "\n",
    "with st.container():\n",
    "    if generate_template:\n",
    "        sql = f\"\"\"select s.ticket_id, s.customer_name, concat(IFF(s.contact_preference = 'Email', '📩', '📲'), ' ', s.contact_preference) as contact_preference, snowflake.cortex.complete('{selected_llm}',\n",
    "        concat('{entered_prompt}','Here is the customer information: Name: ',customer_name,', Contact preference: ', contact_preference))\n",
    "        as llm_response from support_tickets as s join support_tickets_train as t on s.ticket_id = t.ticket_id\n",
    "        where t.mistral_large_response = '{selected_category}' limit 10\"\"\"\n",
    "\n",
    "        with st.status(\"In progress...\") as status:\n",
    "            df_llm_response = session.sql(sql).to_pandas()\n",
    "            st.subheader(\"LLM-generated emails and text messages\")\n",
    "            for row in df_llm_response.itertuples():\n",
    "                status.caption(f\"Ticket ID: `{row.TICKET_ID}`\")\n",
    "                status.caption(f\"To: {row.CUSTOMER_NAME}\")\n",
    "                status.caption(f\"Contact through: {row.CONTACT_PREFERENCE}\")\n",
    "                status.markdown(row.LLM_RESPONSE.replace(\"--\", \"\"))\n",
    "                status.divider()\n",
    "            status.update(label=\"Done!\", state=\"complete\", expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781be9b-41ea-4c40-bdca-985d588bc253",
   "metadata": {
    "name": "additional_resources",
    "collapsed": false
   },
   "source": "You have learnt how to finetune an Large Language Model using Snowflake Cortex. To learn more about Cortex and LLMs, please check out: https://developers.snowflake.com/solutions/?_sft_technology=snowflake-cortex\n"
  }
 ]
}